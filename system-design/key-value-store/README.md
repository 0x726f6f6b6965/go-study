# Key-value store

## About it
- Key-vale stores are distributed hash tables. A key is generated by the hash function and should be unique.

## Requirements
### Functional requirements
- Configurable service
  - We need to provide a configurable service so that different applications can use a range of consistency models.
- Ability to always write
  - The applications should always have the ability to write into the key-value storage.
- Hardware heterogeneity
  - We want to add new servers with different and higher capacities, seamlessly, to our cluster without changing or upgrading existing servers.
### Non-functional requirements
- Scalability
  - We should add or remove the servers as needed with minimal to no disruption to the service availability.
- Fault tolerance
  - The system should operate uninterrupted despite failures in servers or their components.
- Availability
  - The system should run on multiple nodes to prevent a single-node failure.

## Assumptions
- The following assumptions will keep the design simple.
  1. The data centers hosting the service are trusted.
  2. All the required authentication and authorization are already completed.
  3. User requests and responses are relayed over HTTPS.

## API Design

1. `func get(key string) interface{}`
   - The function will return the associated value based on the parameter `key`. One `key` might have different associated values because of the data replication. If the store is configured with a weaker data consistency model, the system will decide to return which associated values. For example, in eventual consistency, there might be more than one value returned against a key.
2. `func put(key string, value interface{}) error`
   - The function will store the `value` associated with the `key` and it will return the error if the operation fails. The system automatically determines where data should be placed.

## Scalability
- With a change in demand, we might need to add or remove nodes. It means that we need to partition data over the nodes in the system to distribute the load across all nodes so it is important to decide on a good way to re-partition and consistent hashing might be a good choice.
### Consistent hashing
- It's an effective way to manage the load over the set of nodes in consistent hashing, imagine that there is a conceptual ring of hashes from `0` to `n-1`, where `n` is the number of available hash values. we use each node's ID to get its hash value and map it to the ring. Each request is completed by the next node that it finds by moving in the clockwise direction in the ring.
- The primary benefit of consistent hashing is that as the nodes join or leave, it ensures that the minimal number of keys need to move. However, the request load isn’t equally divided in practice. Any server that handles a large chunk of data can become a bottleneck in a distributed system. As a result, these are referred to as hotspots. To solve this situation, we can leverage the virtual nodes approach.
### Virtual nodes
- We can add virtual nodes on the hash ring to reduce the load on the actual hotspot nodes. To apply this, we will use multiple hash functions on the same key instead of using one hash function.
- Advantages:
  1. If a node fails or does routine maintenance, the workload is uniformly distributed over other nodes. For each newly accessible node, the other nodes receive nearly equal load when it comes back online or is added to the system.
  2. It’s up to each node to decide how many virtual nodes it’s responsible for, considering the heterogeneity of the physical infrastructure. For example, if a node has roughly double the computational capacity as compared to the others, it can take more load.
## Data replication
- To achieve the requirement of always writing, the peer-to-peer approach seems more suitable than the primary-secondary approach. We’ll replicate the data on multiple hosts to achieve durability and high availability and each data item will be replicated at `n` hosts, where `n` can be configured in the service.
## Data versioning
- It’s necessary to build a way that explicitly accepts the potential of several copies of the same data so that we can avoid the loss of any updates and it's critical to realize that some failure scenarios can lead to multiple copies of the same data in the system. However, these copies might be the same or divergent. Resolving the conflicts among these divergent histories is essential and critical for consistency purposes.
- One of the approaches is using the `TrueTime` function of Spanner as the version. However, if the Spanner doesn't meet our needs, another approach to maintaining causality effectively is by using vector clocks.

## Modify the API design
- After the discussion above, we need to modify the API for the data versioning. For this, we need extra information about which node performed the operation before and what its vector clock value was.
1. `func get(key string) interface{}`
   - The `get` function looks similar but differs in the return value. It returns an object or a collection of conflicting objects along with a `context`, which holds encoded metadata about the object, including details such as the object's version.
2. `func put(context context.Context, key string, value interface{})`
   - The function finds the node where the value should be placed based on the key and stores the value associated with it. The `context` is returned by the system after the `get` operation. If we have a list of objects in the `context` that raises a conflict, we’ll ask the client to resolve it.

## Fault tolerance
- Typically, distributed systems use a quorum-based approach to handle failures. 

## Handle permanent failures
- In the event of permanent failures of nodes, we should keep our replicas synchronized to make our system more durable. We need to speed up the detection of inconsistencies between replicas and reduce the quantity of transferred data. We’ll use Merkle trees for that.
- The advantage of using Merkle trees is that each branch of the Merkle tree can be examined independently without requiring nodes to download the tree or the complete dataset.
- The disadvantage is that when a node joins or departs the system, the tree’s hashes are recalculated because multiple key ranges are affected.


